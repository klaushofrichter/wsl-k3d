defaultRules:
  create: true
  rules:
    etcd: false
    kubeScheduler: false

additionalPrometheusRulesMap:
  rule-name:
    groups:
      - name: ${APP}
        rules:
          - alert: AlertmanagerTest
            expr: vector(1)
            labels:
              severity: info
            annotations:
              summary: "Test Autofire"
              description: "This fires after 30 seconds automatically for test."
              runbook_url: https://www.google.com/search?q=AlertmanagerTest

          - alert: ${APP}Down
            expr: absent(up{job="${APP}-service"} == 1)
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "No ${APP} Service Provision"
              description: "The ${APP}-service does not provide an UP signal."
              runbook_url: https://www.google.com/search?q=KubernetesAppDown


          - alert: ${APP}Pods
            expr: count(${APP}_server_info{job="${APP}-service"}) > 2
            for: 10s
            labels:
              severity: warn
            annotations:
              summary: "More than two pods in ${APP}"
              description: "There are more than two ${APP} running! We may have scaled up even more?"
              runbook_url: https://www.google.com/search?q=kubectl

          - alert: ${APP}Pods
            expr: count(${APP}_server_info{job="${APP}-service"}) > 3
            for: 10s
            labels:
              severity: warn
            annotations:
              summary: "More than three pods in ${APP}"
              description: "There are more than three ${APP} pods running! We may have scaled really hard?"
              runbook_url: https://www.google.com/search?q=scaledown

          - alert: ${APP}Pods
            expr: count(${APP}_server_info{job="${APP}-service"}) > 4
            for: 10s
            labels:
              severity: critical
            annotations:
              summary: "There are {{ $value }} pods in ${APP}"
              description: "There are {{ $value }} ${APP} pods running! We need a bigger machine!"
              runbook_url: https://www.google.com/search?q=reboot

          - alert: ${APP}CPULimit
            expr: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{container="${APP}-container"})/sum(kube_pod_container_resource_limits{resource="cpu", container="${APP}-container"}) > 0.1
            for: 1s
            labels:
              severity: info
            annotations:
              summary: "10% CPU Limit"
              description: "${APP} pods consume more than 10% of CPU Limit"
              runbook_url: https://www.google.com/search?q=dualcorecpu

          - alert: ${APP}CPULimit
            expr: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{container="${APP}-container"})/sum(kube_pod_container_resource_limits{resource="cpu", container="${APP}-container"}) > 0.3
            for: 1s
            labels:
              severity: warn
            annotations:
              summary: "30% CPU Limit"
              description: "${APP} pods consume more than 30% of CPU Limit"
              runbook_url: https://www.google.com/search?q=quadcorecpu

          - alert: ${APP}CPULimit
            expr: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{container="${APP}-container"})/sum(kube_pod_container_resource_limits{resource="cpu", container="${APP}-container"}) > 0.8
            for: 1s
            labels:
              severity: critical
            annotations:
              summary: "80% CPU Limit"
              description: "${APP} pods consume more than 80% of CPU Limit"
              runbook_url: https://www.google.com/search?q=octacorecpu

          - alert: ${APP}CPURequest
            expr: (sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{container="${APP}-container"}) / sum(cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests{container="${APP}-container"})) * 100  > 33
            for: 10s
            labels:
              severity: warn
            annotations:
              summary: "More than 33% CPU Request"
              description: "${APP} pods consume more 33% CPU Request, specifically {{ printf \"%.0f\" $value }}%"
              runbook_url: https://www.google.com/search?q=cpu_request

alertmanager:
  ingress:
    enabled: true
    hosts:
      - localhost
    path: /alert
    ingressClassName: nginx
  admissionWebhooks:
    enabled: false
    patch:
      enabled: false
  tlsProxy.enabled: false
  alertmanagerSpec:
    routePrefix: /alert
  serviceAccount:
    create: true
    name: ""
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""

  config:

    route:

      # everything goes to Slack by default. There are routes to other places when needed. 
      receiver: "${SLACK_OR_NULL}"
      group_by: ["severity"]
      group_wait: 30s
      group_interval: 2m
      repeat_interval: 12h
      routes:
        - match:
            severity: "info"
          receiver: "null"
        - match:
            alertname: "${APP}Down"
          repeat_interval: 2m
        - match:
            severity: "critical"
          repeat_interval: 10m
    inhibit_rules:
      - source_match:
          severity: "warn"
        target_match:
          severity: "info"
        equal:
          - alertname
      - source_match:
          severity: "critical"
        target_match_re:
          severity: "(warn|info)"
        equal:
          - alertname
    receivers:
      - name: "null" 
#
# The Slack configuration is now loaded separately depending on the SLACK_ENABLE feature flag
#
#      - name: "slack"
#        slack_configs:
#          - send_resolved: true
#            api_url: ${SLACKWEBHOOK}
#            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Monitoring Event Notification'
#            text: >-
#              {{ range .Alerts }}
#                *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
#                *Description:* {{ .Annotations.description }}
#                *Runbook:* {{ .Annotations.runbook_url }}
#                *Graph:* <{{ .GeneratorURL }}|Click to see Graph>, if available. Port ${HTTPPORT} may be missing in the URL.
#                *Details:*
#                {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
#                {{ end }}
#              {{ end }}


